{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> At scale: Parallelization on your local computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  system elapsed \n",
      " 12.938   0.462  31.686 \n",
      "   user  system elapsed \n",
      "  8.402   0.325  17.984 \n",
      "   user  system elapsed \n",
      "  8.738   0.296  15.045 \n",
      "   user  system elapsed \n",
      "  8.512   0.225  12.948 \n",
      "   user  system elapsed \n",
      "  7.988   0.232  11.984 \n",
      "   user  system elapsed \n",
      "  9.164   0.221  12.456 \n",
      "   user  system elapsed \n",
      "  8.180   0.296  10.949 \n",
      "   user  system elapsed \n",
      "  8.226   0.235  10.729 \n"
     ]
    }
   ],
   "source": [
    "library(parallel)\n",
    "for (i in seq(2,16,2)) {\n",
    "  cl <- makeCluster(i)\n",
    "  ptm <- proc.time()\n",
    "  parLapply(cl, 1:10000000,\n",
    "            function(exponent){\n",
    "                2^exponent\n",
    "            })\n",
    "  run.time <- proc.time() - ptm\n",
    "  stopCluster(cl)\n",
    "  print (run.time)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <center> At scale: Big Data analytics on Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if (nchar(Sys.getenv(\"SPARK_HOME\")) < 1) {\n",
    "  Sys.setenv(SPARK_HOME = \"/usr/hdp/current/spark-client\")\n",
    "}\n",
    "\n",
    "spark_submit_args <- paste(\"--master yarn-client\",\n",
    "                           \"--executor-memory 32g\",\n",
    "                           \"--num-executors 4\",\n",
    "                           \"--executor-cores 10\",\n",
    "                           paste(\"--conf spark.executorEnv.PATH=\",\n",
    "                                 paste(Sys.getenv(\"PATH\"),\n",
    "                                       \"/usr/local/share/jupyterhub/env/R/lib/R/bin/\",sep=\":\"),\n",
    "                                 sep=\"\"),\n",
    "                           \"sparkr-shell\",sep=\" \")\n",
    "\n",
    "Sys.setenv(\"SPARKR_SUBMIT_ARGS\"=spark_submit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching java with spark-submit command /usr/hdp/current/spark-client/bin/spark-submit  --packages com.databricks:spark-csv_2.11:1.2.0 --master yarn-client --executor-memory 32g --num-executors 4 --executor-cores 10 --conf spark.executorEnv.PATH=/software/hdp/6.0:/software/singularity/2.2/bin:/software/hdf5/1.10.0/bin:/software/openmpi/1.10.3_gcc610/bin:/software/gcc/5.3.0/bin:/software/zeromq/4.1.5/bin:/software/matlab/R2015a/toolbox/distcomp/bin:/software/matlab/R2015a/bin/glnxa64:/software/matlab/R2015a/bin:/software/anaconda3/4.2.0/bin:/usr/lib64/qt-3.3/bin:/bin:/usr/bin:/usr/local/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/opt/mx/bin:/opt/pbs/default/bin:/opt/pbs/default/sbin:/home/lngo/bin:/usr/local/share/jupyterhub/env/R/lib/R/bin/ sparkr-shell /local_scratch/pbs.9015728.pbs02/RtmpwFZ3iI/backend_port195c45839512 \n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in sparkR.init(sparkPackages = \"com.databricks:spark-csv_2.11:1.2.0\"): JVM is not ready after 10 seconds\n",
     "output_type": "error",
     "traceback": [
      "Error in sparkR.init(sparkPackages = \"com.databricks:spark-csv_2.11:1.2.0\"): JVM is not ready after 10 seconds\nTraceback:\n",
      "1. sparkR.init(sparkPackages = \"com.databricks:spark-csv_2.11:1.2.0\")",
      "2. stop(\"JVM is not ready after 10 seconds\")"
     ]
    }
   ],
   "source": [
    "library(SparkR)\n",
    "sc <- sparkR.init(sparkPackages=\"com.databricks:spark-csv_2.11:1.2.0\")\n",
    "sqlContext <- sparkRSQL.init(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in start_shell(master = master, spark_home = spark_home, spark_version = version, : SPARK_HOME directory '/usr/hdp/current/spark-client' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in start_shell(master = master, spark_home = spark_home, spark_version = version, : SPARK_HOME directory '/usr/hdp/current/spark-client' not found\nTraceback:\n",
      "1. spark_connect(master = \"yarn-client\", version = \"1.6.2\")",
      "2. shell_connection(master = master, spark_home = spark_home, app_name = app_name, \n .     version = version, hadoop_version = hadoop_version, shell_args = shell_args, \n .     config = config, service = FALSE, extensions = extensions)",
      "3. start_shell(master = master, spark_home = spark_home, spark_version = version, \n .     app_name = app_name, config = config, jars = spark_config_value(config, \n .         \"sparklyr.jars.default\", list()), packages = spark_config_value(config, \n .         \"sparklyr.defaultPackages\"), extensions = extensions, \n .     environment = environment, shell_args = shell_args, service = service)",
      "4. stop(\"SPARK_HOME directory '\", spark_home, \"' not found\")"
     ]
    }
   ],
   "source": [
    "library(sparklyr)\n",
    "sc <- spark_connect(master = \"yarn-client\", version = \"1.6.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.186   0.151 561.877 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptm <- proc.time()\n",
    "reddit <- read.json(sqlContext, \"hdfs:///datasets/reddit_data/*/*.bz2\")\n",
    "proc.time() - ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- approved_by: string (nullable = true)\n",
      " |-- archived: boolean (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- author_flair_css_class: string (nullable = true)\n",
      " |-- author_flair_text: string (nullable = true)\n",
      " |-- banned_by: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- body_html: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- created: long (nullable = true)\n",
      " |-- created_utc: string (nullable = true)\n",
      " |-- distinguished: string (nullable = true)\n",
      " |-- downs: long (nullable = true)\n",
      " |-- edited: string (nullable = true)\n",
      " |-- gilded: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- link_id: string (nullable = true)\n",
      " |-- mod_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- num_reports: string (nullable = true)\n",
      " |-- parent_id: string (nullable = true)\n",
      " |-- removal_reason: string (nullable = true)\n",
      " |-- replies: string (nullable = true)\n",
      " |-- report_reasons: string (nullable = true)\n",
      " |-- retrieved_on: long (nullable = true)\n",
      " |-- saved: boolean (nullable = true)\n",
      " |-- score: long (nullable = true)\n",
      " |-- score_hidden: boolean (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- ups: long (nullable = true)\n",
      " |-- user_reports: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "NULL\n"
     ]
    }
   ],
   "source": [
    "print (printSchema(reddit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "1659361605"
      ],
      "text/latex": [
       "1659361605"
      ],
      "text/markdown": [
       "1659361605"
      ],
      "text/plain": [
       "[1] 1659361605"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.130   0.104 353.044 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptm <- proc.time()\n",
    "count (reddit)\n",
    "proc.time() - ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sparkR.stop()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "r-3.3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
